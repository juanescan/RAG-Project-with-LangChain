{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cf4245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain openai\n",
    "%pip install -qU langchain-openai\n",
    "%pip install -qU langchain-community langchain-text-splitters langchainhub pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6ebe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d85d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c1bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c12183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juane\\Documents\\GitHub\\RAG-Project-with-LangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f02c306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c2bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bc5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b044542",
   "metadata": {},
   "source": [
    "# Manage vector store\n",
    "\n",
    "## Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "896c89f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['94457bf0-f66d-4be9-8644-32957c10a3a1',\n",
       " 'ee88ac47-e327-4201-b786-272671666a24',\n",
       " '3e51aa47-267f-4499-bb88-a6a9317ef9cd',\n",
       " '5cca575b-6de2-4bb5-8ba6-c99cb796f871',\n",
       " '1bde6c2d-7a33-4bd9-8521-129a7fee519b',\n",
       " '956b5a52-ad02-46cd-ac6f-93ab398698f4',\n",
       " 'ba45feab-a048-4ae7-bd4f-eab27612daaa',\n",
       " '4ae64db7-9964-42b4-b50b-497e38f050f7',\n",
       " 'b17ca59c-2a30-4abe-b29f-503ebafcf96f',\n",
       " '8b5c95b3-32e9-4fee-9112-6dda4cf11902']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62594058",
   "metadata": {},
   "source": [
    "## If we want to delete an item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732527d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[uuids[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09f97a",
   "metadata": {},
   "source": [
    "# Query vector store\n",
    "\n",
    "## Query directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ade2b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82263f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.553289] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5e3b5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9c58d282-9685-4a5e-b779-0900fad4534e', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce7ba98",
   "metadata": {},
   "source": [
    "# Building an app that answers questions about the website's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f79c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (1.0.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (2.12.4)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.42)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bd27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchainhub in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: langgraph in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchainhub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchainhub) (2.32.5)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchainhub) (2.32.4.20250913)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (0.4.42)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.4->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-community) (2.3.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-openai) (2.7.2)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.3.4-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (2.12.4)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (2.3.4)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (1.38.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (0.20.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (34.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (6.0.3)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from chromadb) (14.2.0)\n",
      "Collecting jsonschema>=4.19.0 (from chromadb)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.10.5)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.28.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (1.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.20.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\juane\\documents\\github\\rag-project-with-langchain\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Using cached chromadb-1.3.4-cp39-abi3-win_amd64.whl (20.8 MB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Installing collected packages: jsonschema, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------------------------------------- 0/4 [jsonschema]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   ---------- ----------------------------- 1/4 [opentelemetry-sdk]\n",
      "   --------------- --------------- 2/4 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ------------------------------ --------- 3/4 [chromadb]\n",
      "   ---------------------------------------- 4/4 [chromadb]\n",
      "\n",
      "Successfully installed chromadb-1.3.4 jsonschema-4.25.1 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-sdk-1.38.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchainhub beautifulsoup4 langchain langchain-community langchain-openai langgraph langchain-text-splitters\n",
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf66d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Initialize embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define prompt manually (equivalente a rlm/rag-prompt)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37794a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition involves breaking down complex tasks into smaller and simpler steps to make them more manageable. This can be achieved through techniques like Chain of Thought or Tree of Thoughts, which help models decompose tasks into multiple steps. Different approaches, such as using simple prompts, task-specific instructions, or relying on external planners, can be used for task decomposition.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0aa3a",
   "metadata": {},
   "source": [
    "# 1. Indexing\n",
    "\n",
    "## Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65de25dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e593706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8ec2f",
   "metadata": {},
   "source": [
    "## Splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19ab7c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ae8df",
   "metadata": {},
   "source": [
    "## Storing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1252f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['17073783-8d84-4cef-a7dd-8f08fd4723d1', 'e5ca3089-5225-4b45-a97b-bd8003e0743b', '5412f180-73c9-4685-8d67-8402faf3331f']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa98b3",
   "metadata": {},
   "source": [
    "# 2. Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36aa43d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: Qu es la descomposicin de tareas? \n",
      "Context: \n",
      "La descomposicin de tareas es un proceso que consiste en dividir una tarea compleja en subtareas ms pequeas y manejables.\n",
      "Este enfoque es til para mejorar la eficiencia y la claridad en la ejecucin de tareas complejas.\n",
      " \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Definir el prompt manualmente (equivalente a rlm/rag-prompt)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\")\n",
    "])\n",
    "\n",
    "contexto = \"\"\"\n",
    "La descomposicin de tareas es un proceso que consiste en dividir una tarea compleja en subtareas ms pequeas y manejables.\n",
    "Este enfoque es til para mejorar la eficiencia y la claridad en la ejecucin de tareas complejas.\n",
    "\"\"\"\n",
    "\n",
    "pregunta = \"Qu es la descomposicin de tareas?\"\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": contexto, \"question\": pregunta}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57008494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4816fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "095573bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3dde175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90a1a910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into Problem PDDL, then (2) requests a classical planner to generate a PDDL plan based on an existing Domain PDDL, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into Problem PDDL, then (2) requests a classical planner to generate a PDDL plan based on an existing Domain PDDL, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition is a technique that involves breaking down complex tasks into smaller and simpler steps. This approach helps agents plan ahead and tackle difficult tasks more effectively. Different methods, such as Chain of Thought and Tree of Thoughts, can be used to decompose tasks into manageable components.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7bd8de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(metadata={'start_index': 2578, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into Problem PDDL, then (2) requests a classical planner to generate a PDDL plan based on an existing Domain PDDL, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into Problem PDDL, then (2) requests a classical planner to generate a PDDL plan based on an existing Domain PDDL, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task Decomposition is a technique that involves breaking down complex tasks into smaller and simpler steps. This approach helps models or agents to better understand and plan for achieving the overall task. Different methods like Chain of Thought and Tree of Thoughts are used to decompose tasks into manageable subtasks.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71fe8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| Decom|position| is| a| technique| that| involves| breaking| down| complex| tasks| into| smaller| and| simpler| steps|.| This| approach| helps| models| or| agents| to| better| understand| and| tackle| challenging| tasks| by| thinking| step| by| step|.| Different| methods| like| Chain| of| Thought| and| Tree| of| Thoughts| are| used| to| decom|pose| tasks| into| manageable| components|.||||"
     ]
    }
   ],
   "source": [
    "\n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b891a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bb6d8",
   "metadata": {},
   "source": [
    "# Query analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "358c230a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7500c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5df0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b18f49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63748f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b29acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juane\\Documents\\GitHub\\RAG-Project-with-LangChain\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1963: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='46767899-a65c-4d55-80cb-f391645507f8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39137, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='1f8e8c39-ee43-4e82-bb90-576c71e0aeb0', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39002, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(id='412d7be1-a122-4c35-83bc-d9025c16db40', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32858, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(id='00e34ebd-859a-445e-b32a-af4c4a8cbc25', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35043, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': \"I don't know.\"}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f6c31",
   "metadata": {},
   "source": [
    "# Build a Retrieval Augmented Generation (RAG) App: Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eb6b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langgraph langchain-community beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2532fc",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0576f8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition involves breaking down complex tasks into smaller and simpler steps to make them more manageable. Techniques like Chain of Thought and Tree of Thoughts help models decompose tasks into multiple steps for better performance. Task decomposition can be achieved through various methods, including simple prompting, task-specific instructions, or relying on external classical planners like in the LLM+P approach.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Configurar USER_AGENT\n",
    "os.environ['USER_AGENT'] = 'MyRAGApp/1.0'\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Initialize embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define prompt (SIN usar hub)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Probar el sistema\n",
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2888265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ed75966",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8b29ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f8e7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11cae02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7dd1b7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c77cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b4d7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_fxyMlx5bvzLOaVks3kVrBlqE)\n",
      " Call ID: call_fxyMlx5bvzLOaVks3kVrBlqE\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'start_index': 1638, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. It involves transforming big tasks into multiple manageable tasks to enhance model performance on complex tasks. Chain of Thought (CoT) and Tree of Thoughts are examples of methods that utilize task decomposition to improve the agent's ability to plan ahead and tackle complicated tasks.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65806edd",
   "metadata": {},
   "source": [
    "## Stateful management of chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c3763f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67da60ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_EDtHkmuTtOn7X29jMFAV9dLb)\n",
      " Call ID: call_EDtHkmuTtOn7X29jMFAV9dLb\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps. It involves transforming big tasks into multiple manageable tasks to enhance model performance on difficult tasks. Chain of Thought (CoT) and Tree of Thoughts are examples of methods that utilize task decomposition to improve problem-solving processes.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"What is Task Decomposition?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "467bb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_XZk5tpAIHQwBRsq9vagDgJ5u)\n",
      " Call ID: call_XZk5tpAIHQwBRsq9vagDgJ5u\n",
      "  Args:\n",
      "    query: Common ways of Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Common ways of task decomposition include techniques like Chain of Thought (CoT) and Tree of Thoughts. CoT instructs models to \"think step by step\" to decompose hard tasks into smaller steps, while Tree of Thoughts explores multiple reasoning possibilities at each step by creating a tree structure. These methods use search processes like BFS (breadth-first search) or DFS (depth-first search) to break down tasks into manageable components.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33b2c8",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e9b4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juane\\AppData\\Local\\Temp\\ipykernel_24312\\653244713.py:3: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70a77e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f0d6720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the standard method for Task Decomposition?\n",
      "\n",
      "Once you get the answer, look up common extensions of that method.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_VC0KPMPEcemYxU0mu5WgMLK9)\n",
      " Call ID: call_VC0KPMPEcemYxU0mu5WgMLK9\n",
      "  Args:\n",
      "    query: Standard method for Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'start_index': 1638, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_k98A662VMVSCHmjcESDB9soi)\n",
      " Call ID: call_k98A662VMVSCHmjcESDB9soi\n",
      "  Args:\n",
      "    query: Common extensions of Task Decomposition\n",
      "  retrieve (call_lvtQ8Alx58n5GsZptUnW71AJ)\n",
      " Call ID: call_lvtQ8Alx58n5GsZptUnW71AJ\n",
      "  Args:\n",
      "    query: Chain of Thought (CoT)\n",
      "  retrieve (call_vUjVTeyJMRr10lo528WA5Pli)\n",
      " Call ID: call_vUjVTeyJMRr10lo528WA5Pli\n",
      "  Args:\n",
      "    query: Tree of Thoughts\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Source: {'start_index': 1638, 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to think step by step to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the models thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "### Common Extensions of Task Decomposition:\n",
      "\n",
      "1. **Chain of Thought (CoT):**\n",
      "   - Source: [Link](https://lilianweng.github.io/posts/2023-06-23-agent/)\n",
      "   - Description: CoT is a standard prompting technique for enhancing model performance on complex tasks. It instructs the model to \"think step by step\" to decompose hard tasks into smaller and simpler steps.\n",
      "\n",
      "2. **Tree of Thoughts:**\n",
      "   - Source: [Link](https://lilianweng.github.io/posts/2023-06-23-agent/)\n",
      "   - Description: Tree of Thoughts extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier or majority vote.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
